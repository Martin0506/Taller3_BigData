{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d374d5",
   "metadata": {},
   "source": [
    "## Data Pipelines - Prefect - Example and Workshop\n",
    "### Big Data Tools \n",
    "#### M.Sc. in Applied Analytics (coterminal course)\n",
    "Fac. de Ingenier√≠a -  Universidad de la Sabana<br>\n",
    "Prof.: Hugo Franco, Ph.D.\n",
    "\n",
    "Workshop resolved by: David Lopez - Martin Jerez - Juliana Espinel - Harold Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aba2287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:51.597 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8710</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:51.597 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8710\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.597 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Wheat Seed Analysis Pipeline'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.597 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - Beginning flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m for flow\u001b[1;35m 'Wheat Seed Analysis Pipeline'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.634 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Creating directory: ./data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.634 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Creating directory: ./data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.636 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Creating directory: ./output\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.636 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Creating directory: ./output\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.638 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Directory creation task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.638 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Directory creation task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'create_directories' took 0.0079 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.646 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.646 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.669 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Attempting Kaggle API authentication...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.669 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Attempting Kaggle API authentication...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.671 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Kaggle API authentication successful.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.671 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Kaggle API authentication successful.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.674 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Authentication task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.674 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Authentication task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'api_authenticate' took 0.0073 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.679 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.679 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.702 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Downloading dataset 'sushilyeotiwad/wheat-seed-dataset' to './data'...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.702 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Downloading dataset 'sushilyeotiwad/wheat-seed-dataset' to './data'...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sushilyeotiwad/wheat-seed-dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.183 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Dataset download and unzip completed successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.183 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Dataset download and unzip completed successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.185 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Download task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.185 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Download task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'download_dataset' took 0.4854 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.190 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.190 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.193 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - ‚úÖ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.193 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - ‚úÖ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.212 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - Loading CSV file from ./data\\seeds_dataset.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.212 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - Loading CSV file from ./data\\seeds_dataset.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.234 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - CSV file loaded successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.234 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - CSV file loaded successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.235 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - CSV loading task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.235 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - CSV loading task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'load_csv' took 0.0261 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.240 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.240 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.261 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Performing data cleansing...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.261 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Performing data cleansing...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.266 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Data cleansing completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.266 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Data cleansing completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.268 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Data transformation task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.268 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Data transformation task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'transform_data' took 0.0090 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.272 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.272 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.377 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Creating table if not exists...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.377 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Creating table if not exists...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.381 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Table created/verified successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.381 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Table created/verified successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.383 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Inserting data into PostgreSQL...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.383 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Inserting data into PostgreSQL...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.532 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Successfully inserted 210 records into PostgreSQL.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.532 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Successfully inserted 210 records into PostgreSQL.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'load_data' took 0.2445 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.544 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.544 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.568 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - Analyzing feature correlations...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.568 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - Analyzing feature correlations...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.572 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - The lowest absolute correlation is 0.0111, between ('Length_of_kernel_groove', 'Asymmetry_coefficient')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.572 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - The lowest absolute correlation is 0.0111, between ('Length_of_kernel_groove', 'Asymmetry_coefficient')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.943 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - Correlation analysis completed and heatmap saved to ./output\\correlation_heatmap.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.943 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - Correlation analysis completed and heatmap saved to ./output\\correlation_heatmap.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'analyze_correlations' took 0.3778 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.948 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.948 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.970 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Elbow Method Analysis-8d5' - Performing Elbow Method analysis...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.970 | \u001b[36mINFO\u001b[0m    | Task run 'Elbow Method Analysis-8d5' - Performing Elbow Method analysis...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:00.314 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Elbow Method Analysis-8d5' - Elbow Method analysis completed and plot saved to ./output\\elbow_method.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:00.314 | \u001b[36mINFO\u001b[0m    | Task run 'Elbow Method Analysis-8d5' - Elbow Method analysis completed and plot saved to ./output\\elbow_method.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'elbow_method_analysis' took 2.3490 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:00.320 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Elbow Method Analysis-8d5' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:00.320 | \u001b[36mINFO\u001b[0m    | Task run 'Elbow Method Analysis-8d5' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:00.353 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering-900' - Performing K-means clustering...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:00.353 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering-900' - Performing K-means clustering...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.033 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering-900' - Clustering completed and visualization saved to ./output\\kmeans_clustering.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.033 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering-900' - Clustering completed and visualization saved to ./output\\kmeans_clustering.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'perform_kmeans_clustering' took 0.6826 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.039 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering-900' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.039 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering-900' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.070 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Performing K-means clustering with centroids...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.070 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Performing K-means clustering with centroids...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.545 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Clustering with centroids completed and visualization saved to ./output\\kmeans_clustering_with_centroids.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.545 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Clustering with centroids completed and visualization saved to ./output\\kmeans_clustering_with_centroids.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'perform_kmeans_clustering_with_centroids' took 0.4782 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.550 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.550 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.556 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - ‚úÖ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.556 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - ‚úÖ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.605 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.605 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed. Lowest correlation pair: ('Length_of_kernel_groove', 'Asymmetry_coefficient')\n",
      "Cluster centroids: [[5.60078947 5.34238596]\n",
      " [3.71363218 5.52770115]\n",
      " [2.04107879 5.30710606]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from prefect import flow, task, get_run_logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Usar backend no interactivo para evitar problemas de visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from kaggle import KaggleApi\n",
    "import logging\n",
    "import time\n",
    "from functools import wraps\n",
    "import psycopg2\n",
    "\n",
    "# Environment setup\n",
    "os.environ['OMP_NUM_THREADS'] = '1'  # Prevent problems with threading\n",
    "\n",
    "# Constants\n",
    "LOCAL_KAGGLE_DIR = './auth'\n",
    "DOWNLOAD_DIRECTORY = './data'\n",
    "OUTPUT_DIRECTORY = './output'\n",
    "TARGET_DATASET = 'sushilyeotiwad/wheat-seed-dataset'\n",
    "\n",
    "# Decorador para manejar conexiones a PostgreSQL\n",
    "def with_postgresql_connection(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"localhost\",\n",
    "            port=5433,\n",
    "            database=\"bigdatatools1\",\n",
    "            user=\"psqluser\",\n",
    "            password=\"psqlpass\"\n",
    "        )\n",
    "        try:\n",
    "            cur = conn.cursor()\n",
    "            result = func(cur, *args, **kwargs)\n",
    "            conn.commit()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            raise e\n",
    "        finally:\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "    return wrapper\n",
    "\n",
    "# Timing decorator to report task duration\n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Task '{func.__name__}' took {duration:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Helper functions\n",
    "def get_directory_size(path='.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def format_size(size_bytes):\n",
    "    \"\"\"Convierte bytes en una unidad legible (KB, MB, GB).\"\"\"\n",
    "    if size_bytes < 1024:\n",
    "        return f\"{size_bytes} B\"\n",
    "    elif size_bytes < 1024**2:\n",
    "        return f\"{size_bytes / 1024:.2f} KB\"\n",
    "    elif size_bytes < 1024**3:\n",
    "        return f\"{size_bytes / (1024**2):.2f} MB\"\n",
    "    else:\n",
    "        return f\"{size_bytes / (1024**3):.2f} GB\"\n",
    "\n",
    "# Task: Create necessary directories\n",
    "@task(name=\"Create Directories\")\n",
    "@timing_decorator\n",
    "def create_directories():\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        # Create download directory\n",
    "        if not os.path.exists(DOWNLOAD_DIRECTORY):\n",
    "            logger.info(f\"Creating directory: {DOWNLOAD_DIRECTORY}\")\n",
    "            os.makedirs(DOWNLOAD_DIRECTORY)\n",
    "        else:\n",
    "            logger.info(f\"Directory {DOWNLOAD_DIRECTORY} already exists.\")\n",
    "            \n",
    "        # Create output directory for visualizations\n",
    "        if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "            logger.info(f\"Creating directory: {OUTPUT_DIRECTORY}\")\n",
    "            os.makedirs(OUTPUT_DIRECTORY)\n",
    "        else:\n",
    "            logger.info(f\"Directory {OUTPUT_DIRECTORY} already exists.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create directories: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Directory creation task completed.\")\n",
    "\n",
    "# Task: Authenticate with Kaggle\n",
    "@task(retries=3, retry_delay_seconds=10, name=\"Authenticate\")\n",
    "@timing_decorator\n",
    "def api_authenticate():\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Attempting Kaggle API authentication...\")\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        logger.info(\"Kaggle API authentication successful.\")\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kaggle authentication failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Authentication task completed.\")\n",
    "\n",
    "def report_download_size(path='.'):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            logger = get_run_logger()\n",
    "            result = func(*args, **kwargs)\n",
    "            size_bytes = get_directory_size(path)\n",
    "            logger.info(f\"‚úÖ Dataset downloaded. Total size in '{path}': \"\n",
    "                  f\"{size_bytes:,} bytes ({format_size(size_bytes)})\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Task: Download dataset from Kaggle\n",
    "@report_download_size(DOWNLOAD_DIRECTORY)\n",
    "@task(retries=3, retry_delay_seconds=10, name=\"Download Dataset\")\n",
    "@timing_decorator\n",
    "def download_dataset(kaggle_api):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(f\"Downloading dataset '{TARGET_DATASET}' to '{DOWNLOAD_DIRECTORY}'...\")\n",
    "        kaggle_api.dataset_download_files(TARGET_DATASET, path=DOWNLOAD_DIRECTORY, unzip=True)\n",
    "        logger.info(\"Dataset download and unzip completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Dataset download failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Download task completed.\")\n",
    "\n",
    "# Task: Load CSV into DataFrame\n",
    "@task(name=\"Load CSV\")\n",
    "@timing_decorator\n",
    "def load_csv():\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        csv_path = os.path.join(DOWNLOAD_DIRECTORY, 'seeds_dataset.csv')\n",
    "        logger.info(f\"Loading CSV file from {csv_path}\")\n",
    "        df_seeds = pd.read_csv(csv_path)\n",
    "        logger.info(\"CSV file loaded successfully.\")\n",
    "        return df_seeds\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"CSV file not found: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading CSV: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"CSV loading task completed.\")\n",
    "\n",
    "# Task: Transform data (cleansing)\n",
    "@task(name=\"Transform Data\")\n",
    "@timing_decorator\n",
    "def transform_data(df_seeds):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing data cleansing...\")\n",
    "        # Basic data cleansing: Drop the 'Class' column\n",
    "        df_clustering = df_seeds.drop('Class_(1, 2, 3)', axis=1)\n",
    "        # Additional cleansing: Handle missing values and duplicates\n",
    "        df_clustering = df_clustering.dropna().drop_duplicates()\n",
    "        logger.info(\"Data cleansing completed.\")\n",
    "        return df_clustering\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Column not found during transformation: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transformation failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Data transformation task completed.\")\n",
    "\n",
    "# Task: Load data into PostgreSQL\n",
    "@task(name=\"Load Data to PostgreSQL\")\n",
    "@timing_decorator\n",
    "@with_postgresql_connection\n",
    "def load_data(cur, df_clustering):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        # Create table if it doesn't exist\n",
    "        logger.info(\"Creating table if not exists...\")\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS wheat_seeds_clustering (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            area REAL,\n",
    "            perimeter REAL,\n",
    "            compactness REAL,\n",
    "            length_of_kernel REAL,\n",
    "            width_of_kernel REAL,\n",
    "            asymmetry_coefficient REAL,\n",
    "            length_of_kernel_groove REAL\n",
    "        )\n",
    "        \"\"\"\n",
    "        cur.execute(create_table_query)\n",
    "        logger.info(\"Table created/verified successfully.\")\n",
    "        \n",
    "        # Insert data from DataFrame\n",
    "        logger.info(\"Inserting data into PostgreSQL...\")\n",
    "        for _, row in df_clustering.iterrows():\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO wheat_seeds_clustering \n",
    "            (area, perimeter, compactness, length_of_kernel, width_of_kernel, asymmetry_coefficient, length_of_kernel_groove)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.execute(insert_query, tuple(row))\n",
    "        \n",
    "        logger.info(f\"Successfully inserted {len(df_clustering)} records into PostgreSQL.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data to PostgreSQL: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Analyze correlations\n",
    "@task(name=\"Analyze Correlations\")\n",
    "@timing_decorator\n",
    "def analyze_correlations(df_clustering):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Analyzing feature correlations...\")\n",
    "        \n",
    "        # Calculate the correlation matrix\n",
    "        correlation_matrix = df_clustering.corr()\n",
    "\n",
    "        # Find the pair of variables with the lowest absolute correlation\n",
    "        lower_triangle = correlation_matrix.mask(np.triu(np.ones(correlation_matrix.shape)).astype(bool))\n",
    "        lowest_corr = lower_triangle.stack().abs().min()\n",
    "        lowest_corr_pair = lower_triangle.stack().abs().idxmin()\n",
    "\n",
    "        # Print the lowest correlation and the corresponding pair of variables\n",
    "        logger.info(f\"The lowest absolute correlation is {lowest_corr:.4f}, between {lowest_corr_pair}\")\n",
    "\n",
    "        # Plot a heatmap of the correlation matrix for visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title('Correlation Matrix of Seed Features')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'correlation_heatmap.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Correlation analysis completed and heatmap saved to {output_path}.\")\n",
    "        \n",
    "        return lowest_corr_pair\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in correlation analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Elbow Method Analysis\n",
    "@task(name=\"Elbow Method Analysis\")\n",
    "@timing_decorator\n",
    "def elbow_method_analysis(df_clustering):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing Elbow Method analysis...\")\n",
    "        \n",
    "        # Select the two variables for clustering\n",
    "        X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "        # Determine the optimal number of clusters using the Elbow Method\n",
    "        inertia = []\n",
    "        for i in range(1, 11):\n",
    "            kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "            kmeans.fit(X)\n",
    "            inertia.append(kmeans.inertia_)\n",
    "\n",
    "        # Plot the Elbow Method results\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(range(1, 11), inertia, marker='o')\n",
    "        plt.title('Elbow Method for Optimal K')\n",
    "        plt.xlabel('Number of Clusters (K)')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'elbow_method.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Elbow Method analysis completed and plot saved to {output_path}.\")\n",
    "        \n",
    "        # Based on the Elbow plot, choose the optimal number of clusters\n",
    "        optimal_k = 3\n",
    "        return optimal_k\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in Elbow Method analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Perform clustering without centroids\n",
    "@task(name=\"Perform KMeans Clustering\")\n",
    "@timing_decorator\n",
    "def perform_kmeans_clustering(df_clustering, optimal_k=3):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing K-means clustering...\")\n",
    "        \n",
    "        # Variables para clustering\n",
    "        X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "        # Entrenar KMeans con K √≥ptimo\n",
    "        kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        df_clustering['cluster'] = kmeans_model.fit_predict(X)\n",
    "\n",
    "        # Visualizar resultados sin centroides\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(\n",
    "            df_clustering['Asymmetry_coefficient'], \n",
    "            df_clustering['Length_of_kernel_groove'], \n",
    "            c=df_clustering['cluster'], cmap='viridis'\n",
    "        )\n",
    "        plt.title(f'K-means Clustering of Seeds (K={optimal_k})')\n",
    "        plt.xlabel('Asymmetry_coefficient')\n",
    "        plt.ylabel('Length_of_kernel_groove')\n",
    "        plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'kmeans_clustering.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        logger.info(f\"Clustering completed and visualization saved to {output_path}.\")\n",
    "        \n",
    "        return df_clustering\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in clustering: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Perform clustering with centroids\n",
    "@task(name=\"Perform KMeans Clustering with Centroids\")\n",
    "@timing_decorator\n",
    "def perform_kmeans_clustering_with_centroids(df_clustering, optimal_k=3):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing K-means clustering with centroids...\")\n",
    "        \n",
    "        # Variables para clustering\n",
    "        X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "        # Entrenar KMeans con K √≥ptimo\n",
    "        kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        df_clustering['cluster'] = kmeans_model.fit_predict(X)\n",
    "\n",
    "        # Centroides\n",
    "        centroids = kmeans_model.cluster_centers_\n",
    "\n",
    "        # Visualizar resultados con centroides\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(\n",
    "            df_clustering['Asymmetry_coefficient'], \n",
    "            df_clustering['Length_of_kernel_groove'], \n",
    "            c=df_clustering['cluster'], cmap='viridis'\n",
    "        )\n",
    "        plt.scatter(\n",
    "            centroids[:, 0], centroids[:, 1], \n",
    "            c='red', marker='X', s=200, label='Centroids'\n",
    "        )\n",
    "        plt.title(f'K-means Clustering of Seeds (K={optimal_k})')\n",
    "        plt.xlabel('Asymmetry_coefficient')\n",
    "        plt.ylabel('Length_of_kernel_groove')\n",
    "        plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'kmeans_clustering_with_centroids.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        logger.info(f\"Clustering with centroids completed and visualization saved to {output_path}.\")\n",
    "        \n",
    "        return df_clustering, centroids\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in clustering with centroids: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Main Flow: Orchestrate the pipeline\n",
    "@flow(name=\"Wheat Seed Analysis Pipeline\")\n",
    "@report_download_size(DOWNLOAD_DIRECTORY)\n",
    "def complete_analysis_pipeline():\n",
    "    create_directories()\n",
    "    kaggle_api = api_authenticate()\n",
    "    download_dataset(kaggle_api)\n",
    "    df_seeds = load_csv()\n",
    "    df_clustering = transform_data(df_seeds)\n",
    "    load_data(df_clustering)\n",
    "    lowest_corr_pair = analyze_correlations(df_clustering)\n",
    "    optimal_k = elbow_method_analysis(df_clustering)\n",
    "    df_clustered = perform_kmeans_clustering(df_clustering, optimal_k)\n",
    "    df_clustered_with_centroids, centroids = perform_kmeans_clustering_with_centroids(df_clustering, optimal_k)\n",
    "    \n",
    "    return df_clustered, lowest_corr_pair, centroids\n",
    "\n",
    "# Run the flow\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df_clustered, lowest_corr_pair, centroids = complete_analysis_pipeline()\n",
    "        print(f\"Analysis completed. Lowest correlation pair: {lowest_corr_pair}\")\n",
    "        print(f\"Cluster centroids: {centroids}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline execution failed: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38e0ab",
   "metadata": {},
   "source": [
    "### Basic (Unsupervised) Machine Learning analytics method\n",
    " Determine, by clustering, a sound number of species within the wheat seed dataset\n",
    "\n",
    " Firstly, identify the less correlated pair of features and use them as the representation for the instances in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a54896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # Calculate the correlation matrix.\n",
    "# correlation_matrix = df_clustering.corr()\n",
    "\n",
    "# # Find the pair of variables with the lowest absolute correlation.\n",
    "# # We take the upper triangle of the correlation matrix and flatten it, and ignore the diagonal (which are all 1).\n",
    "# # We then find the minimum value and the corresponding row and column.\n",
    "# lower_triangle = correlation_matrix.mask(np.triu(np.ones(correlation_matrix.shape)).astype(bool))\n",
    "# lowest_corr = lower_triangle.stack().abs().min()\n",
    "# lowest_corr_pair = lower_triangle.stack().abs().idxmin()\n",
    "\n",
    "# # Print the lowest correlation and the corresponding pair of variables.\n",
    "# print(f\"The lowest absolute correlation is {lowest_corr:.4f}, between {lowest_corr_pair}\")\n",
    "\n",
    "# # Plot a heatmap of the correlation matrix for visualization.\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# plt.title('Correlation Matrix of Seed Features')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('correlation_heatmap.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dc263",
   "metadata": {},
   "source": [
    "Now, use the `KMeans` clustering method to perform an unsupervised approach to the identification of the number of species in the dataset, according to the observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c0a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# # Select the two variables for clustering.\n",
    "# X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "# # Determine the optimal number of clusters using the Elbow Method.\n",
    "# inertia = []\n",
    "# for i in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "#     kmeans.fit(X)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "\n",
    "# # Plot the Elbow Method results.\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(range(1, 11), inertia, marker='o')\n",
    "# plt.title('Elbow Method for Optimal K')\n",
    "# plt.xlabel('Number of Clusters (K)')\n",
    "# plt.ylabel('Inertia')\n",
    "# plt.xticks(range(1, 11))\n",
    "# plt.grid(True)\n",
    "# plt.savefig('elbow_method.png')\n",
    "# plt.show()\n",
    "\n",
    "# # Based on the Elbow plot, choose the optimal number of clusters.\n",
    "# # For this dataset, the 'Class' column suggests ?? classes, and the elbow method plot shows a good elbow at k=??.\n",
    "# optimal_k = 3\n",
    "\n",
    "# # Perform K-means clustering with the optimal number of clusters.\n",
    "# kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "# df_clustering['cluster'] = kmeans_model.fit_predict(X)\n",
    "\n",
    "# # Visualize the clustering results.\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# scatter = plt.scatter(df_clustering['Asymmetry_coefficient'], df_clustering['Length_of_kernel_groove'], c=df_clustering['cluster'], cmap='viridis')\n",
    "# plt.title('K-means Clustering of Seeds (K=3)')\n",
    "# plt.xlabel('Asymmetry_coefficient')\n",
    "# plt.ylabel('Length_of_kernel_groove')\n",
    "# plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "# plt.grid(True)\n",
    "# plt.savefig('kmeans_clustering_plot.png')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027d2f4",
   "metadata": {},
   "source": [
    "__Challenges (Workshop 3, part 2):__\n",
    "1. Organize the code of the example and complete the data pipeline: \n",
    "    - Use `try-except-finally` blocks as required \n",
    "    - Every individual process must be wrapped as a `task` using the corresponding decorator and its parameters when necessary. \n",
    "    - Create a `transform_data` task focused on data cleansing\n",
    "    - Create a `load_data` task to create a table in a Dockerized PostgreSQL database and populate with with the clustering-oriented Dataframe\n",
    "    - Invoke the tasks in the proper order in the `flow`\n",
    "    - Use the `timing_decorator` to report the duration of each task \n",
    "1. Using the function get_directory_size, create a decorator to get and report the size of the downloaded dataset (size in bytes of the download folder)\n",
    "1. Report the size in the previous question in a human readable unit\n",
    "1. Use the attribute kmeans.cluster_centers_ and scatter plot to add the centroids of the best KMeans model (best K parameter) to the scatter plot\n",
    "    - `centroids = kmeans.cluster_centers_`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
