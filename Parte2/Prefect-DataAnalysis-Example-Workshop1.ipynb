{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d374d5",
   "metadata": {},
   "source": [
    "## Data Pipelines - Prefect - Example and Workshop\n",
    "### Big Data Tools \n",
    "#### M.Sc. in Applied Analytics (coterminal course)\n",
    "Fac. de Ingeniería -  Universidad de la Sabana<br>\n",
    "Prof.: Hugo Franco, Ph.D.\n",
    "\n",
    "Workshop resolved by: David Lopez - Martin Jerez - Juliana Espinel - Harold Vargas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aba2287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:51.597 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect - Starting temporary server on <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:8710</span>\n",
       "See <span style=\"color: #0000ff; text-decoration-color: #0000ff\">https://docs.prefect.io/v3/concepts/server#how-to-guides</span> for more information on running a dedicated Prefect server.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:51.597 | \u001b[36mINFO\u001b[0m    | prefect - Starting temporary server on \u001b[94mhttp://127.0.0.1:8710\u001b[0m\n",
       "See \u001b[94mhttps://docs.prefect.io/v3/concepts/server#how-to-guides\u001b[0m for more information on running a dedicated Prefect server.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.597 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'Wheat Seed Analysis Pipeline'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.597 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - Beginning flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m for flow\u001b[1;35m 'Wheat Seed Analysis Pipeline'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.634 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Creating directory: ./data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.634 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Creating directory: ./data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.636 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Creating directory: ./output\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.636 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Creating directory: ./output\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.638 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Directory creation task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.638 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Directory creation task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'create_directories' took 0.0079 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.646 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Create Directories-92b' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.646 | \u001b[36mINFO\u001b[0m    | Task run 'Create Directories-92b' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.669 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Attempting Kaggle API authentication...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.669 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Attempting Kaggle API authentication...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.671 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Kaggle API authentication successful.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.671 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Kaggle API authentication successful.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.674 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Authentication task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.674 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Authentication task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'api_authenticate' took 0.0073 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.679 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Authenticate-cec' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.679 | \u001b[36mINFO\u001b[0m    | Task run 'Authenticate-cec' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:56.702 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Downloading dataset 'sushilyeotiwad/wheat-seed-dataset' to './data'...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:56.702 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Downloading dataset 'sushilyeotiwad/wheat-seed-dataset' to './data'...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/sushilyeotiwad/wheat-seed-dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.183 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Dataset download and unzip completed successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.183 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Dataset download and unzip completed successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.185 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Download task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.185 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Download task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'download_dataset' took 0.4854 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.190 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Download Dataset-b4a' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.190 | \u001b[36mINFO\u001b[0m    | Task run 'Download Dataset-b4a' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.193 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - ✅ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.193 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - ✅ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.212 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - Loading CSV file from ./data\\seeds_dataset.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.212 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - Loading CSV file from ./data\\seeds_dataset.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.234 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - CSV file loaded successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.234 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - CSV file loaded successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.235 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - CSV loading task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.235 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - CSV loading task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'load_csv' took 0.0261 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.240 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load CSV-7f8' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.240 | \u001b[36mINFO\u001b[0m    | Task run 'Load CSV-7f8' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.261 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Performing data cleansing...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.261 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Performing data cleansing...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.266 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Data cleansing completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.266 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Data cleansing completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.268 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Data transformation task completed.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.268 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Data transformation task completed.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'transform_data' took 0.0090 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.272 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Transform Data-1f7' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.272 | \u001b[36mINFO\u001b[0m    | Task run 'Transform Data-1f7' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.377 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Creating table if not exists...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.377 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Creating table if not exists...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.381 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Table created/verified successfully.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.381 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Table created/verified successfully.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.383 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Inserting data into PostgreSQL...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.383 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Inserting data into PostgreSQL...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.532 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Successfully inserted 210 records into PostgreSQL.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.532 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Successfully inserted 210 records into PostgreSQL.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'load_data' took 0.2445 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.544 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Load Data to PostgreSQL-a68' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.544 | \u001b[36mINFO\u001b[0m    | Task run 'Load Data to PostgreSQL-a68' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.568 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - Analyzing feature correlations...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.568 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - Analyzing feature correlations...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.572 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - The lowest absolute correlation is 0.0111, between ('Length_of_kernel_groove', 'Asymmetry_coefficient')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.572 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - The lowest absolute correlation is 0.0111, between ('Length_of_kernel_groove', 'Asymmetry_coefficient')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.943 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - Correlation analysis completed and heatmap saved to ./output\\correlation_heatmap.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.943 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - Correlation analysis completed and heatmap saved to ./output\\correlation_heatmap.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'analyze_correlations' took 0.3778 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.948 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Analyze Correlations-229' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.948 | \u001b[36mINFO\u001b[0m    | Task run 'Analyze Correlations-229' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:03:57.970 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Elbow Method Analysis-8d5' - Performing Elbow Method analysis...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:03:57.970 | \u001b[36mINFO\u001b[0m    | Task run 'Elbow Method Analysis-8d5' - Performing Elbow Method analysis...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:00.314 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Elbow Method Analysis-8d5' - Elbow Method analysis completed and plot saved to ./output\\elbow_method.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:00.314 | \u001b[36mINFO\u001b[0m    | Task run 'Elbow Method Analysis-8d5' - Elbow Method analysis completed and plot saved to ./output\\elbow_method.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'elbow_method_analysis' took 2.3490 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:00.320 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Elbow Method Analysis-8d5' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:00.320 | \u001b[36mINFO\u001b[0m    | Task run 'Elbow Method Analysis-8d5' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:00.353 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering-900' - Performing K-means clustering...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:00.353 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering-900' - Performing K-means clustering...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.033 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering-900' - Clustering completed and visualization saved to ./output\\kmeans_clustering.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.033 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering-900' - Clustering completed and visualization saved to ./output\\kmeans_clustering.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'perform_kmeans_clustering' took 0.6826 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.039 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering-900' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.039 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering-900' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.070 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Performing K-means clustering with centroids...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.070 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Performing K-means clustering with centroids...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\BigData\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.545 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Clustering with centroids completed and visualization saved to ./output\\kmeans_clustering_with_centroids.png.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.545 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Clustering with centroids completed and visualization saved to ./output\\kmeans_clustering_with_centroids.png.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 'perform_kmeans_clustering_with_centroids' took 0.4782 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.550 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.550 | \u001b[36mINFO\u001b[0m    | Task run 'Perform KMeans Clustering with Centroids-2e5' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.556 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - ✅ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.556 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - ✅ Dataset downloaded. Total size in './data': 9,627 bytes (9.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">12:04:01.605 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'eccentric-bandicoot'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "12:04:01.605 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'eccentric-bandicoot'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis completed. Lowest correlation pair: ('Length_of_kernel_groove', 'Asymmetry_coefficient')\n",
      "Cluster centroids: [[5.60078947 5.34238596]\n",
      " [3.71363218 5.52770115]\n",
      " [2.04107879 5.30710606]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from prefect import flow, task, get_run_logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Usar backend no interactivo para evitar problemas de visualización\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from kaggle import KaggleApi\n",
    "import logging\n",
    "import time\n",
    "from functools import wraps\n",
    "import psycopg2\n",
    "\n",
    "# Environment setup\n",
    "os.environ['OMP_NUM_THREADS'] = '1'  # Prevent problems with threading\n",
    "\n",
    "# Constants\n",
    "LOCAL_KAGGLE_DIR = './auth'\n",
    "DOWNLOAD_DIRECTORY = './data'\n",
    "OUTPUT_DIRECTORY = './output'\n",
    "TARGET_DATASET = 'sushilyeotiwad/wheat-seed-dataset'\n",
    "\n",
    "# Decorador para manejar conexiones a PostgreSQL\n",
    "def with_postgresql_connection(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"localhost\",\n",
    "            port=5433,\n",
    "            database=\"bigdatatools1\",\n",
    "            user=\"psqluser\",\n",
    "            password=\"psqlpass\"\n",
    "        )\n",
    "        try:\n",
    "            cur = conn.cursor()\n",
    "            result = func(cur, *args, **kwargs)\n",
    "            conn.commit()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            raise e\n",
    "        finally:\n",
    "            cur.close()\n",
    "            conn.close()\n",
    "    return wrapper\n",
    "\n",
    "# Timing decorator to report task duration\n",
    "def timing_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Task '{func.__name__}' took {duration:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Helper functions\n",
    "def get_directory_size(path='.'):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size\n",
    "\n",
    "def format_size(size_bytes):\n",
    "    \"\"\"Convierte bytes en una unidad legible (KB, MB, GB).\"\"\"\n",
    "    if size_bytes < 1024:\n",
    "        return f\"{size_bytes} B\"\n",
    "    elif size_bytes < 1024**2:\n",
    "        return f\"{size_bytes / 1024:.2f} KB\"\n",
    "    elif size_bytes < 1024**3:\n",
    "        return f\"{size_bytes / (1024**2):.2f} MB\"\n",
    "    else:\n",
    "        return f\"{size_bytes / (1024**3):.2f} GB\"\n",
    "\n",
    "# Task: Create necessary directories\n",
    "@task(name=\"Create Directories\")\n",
    "@timing_decorator\n",
    "def create_directories():\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        # Create download directory\n",
    "        if not os.path.exists(DOWNLOAD_DIRECTORY):\n",
    "            logger.info(f\"Creating directory: {DOWNLOAD_DIRECTORY}\")\n",
    "            os.makedirs(DOWNLOAD_DIRECTORY)\n",
    "        else:\n",
    "            logger.info(f\"Directory {DOWNLOAD_DIRECTORY} already exists.\")\n",
    "            \n",
    "        # Create output directory for visualizations\n",
    "        if not os.path.exists(OUTPUT_DIRECTORY):\n",
    "            logger.info(f\"Creating directory: {OUTPUT_DIRECTORY}\")\n",
    "            os.makedirs(OUTPUT_DIRECTORY)\n",
    "        else:\n",
    "            logger.info(f\"Directory {OUTPUT_DIRECTORY} already exists.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create directories: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Directory creation task completed.\")\n",
    "\n",
    "# Task: Authenticate with Kaggle\n",
    "@task(retries=3, retry_delay_seconds=10, name=\"Authenticate\")\n",
    "@timing_decorator\n",
    "def api_authenticate():\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Attempting Kaggle API authentication...\")\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        logger.info(\"Kaggle API authentication successful.\")\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Kaggle authentication failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Authentication task completed.\")\n",
    "\n",
    "def report_download_size(path='.'):\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            logger = get_run_logger()\n",
    "            result = func(*args, **kwargs)\n",
    "            size_bytes = get_directory_size(path)\n",
    "            logger.info(f\"✅ Dataset downloaded. Total size in '{path}': \"\n",
    "                  f\"{size_bytes:,} bytes ({format_size(size_bytes)})\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Task: Download dataset from Kaggle\n",
    "@report_download_size(DOWNLOAD_DIRECTORY)\n",
    "@task(retries=3, retry_delay_seconds=10, name=\"Download Dataset\")\n",
    "@timing_decorator\n",
    "def download_dataset(kaggle_api):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(f\"Downloading dataset '{TARGET_DATASET}' to '{DOWNLOAD_DIRECTORY}'...\")\n",
    "        kaggle_api.dataset_download_files(TARGET_DATASET, path=DOWNLOAD_DIRECTORY, unzip=True)\n",
    "        logger.info(\"Dataset download and unzip completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Dataset download failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Download task completed.\")\n",
    "\n",
    "# Task: Load CSV into DataFrame\n",
    "@task(name=\"Load CSV\")\n",
    "@timing_decorator\n",
    "def load_csv():\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        csv_path = os.path.join(DOWNLOAD_DIRECTORY, 'seeds_dataset.csv')\n",
    "        logger.info(f\"Loading CSV file from {csv_path}\")\n",
    "        df_seeds = pd.read_csv(csv_path)\n",
    "        logger.info(\"CSV file loaded successfully.\")\n",
    "        return df_seeds\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"CSV file not found: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading CSV: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"CSV loading task completed.\")\n",
    "\n",
    "# Task: Transform data (cleansing)\n",
    "@task(name=\"Transform Data\")\n",
    "@timing_decorator\n",
    "def transform_data(df_seeds):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing data cleansing...\")\n",
    "        # Basic data cleansing: Drop the 'Class' column\n",
    "        df_clustering = df_seeds.drop('Class_(1, 2, 3)', axis=1)\n",
    "        # Additional cleansing: Handle missing values and duplicates\n",
    "        df_clustering = df_clustering.dropna().drop_duplicates()\n",
    "        logger.info(\"Data cleansing completed.\")\n",
    "        return df_clustering\n",
    "    except KeyError as e:\n",
    "        logger.error(f\"Column not found during transformation: {str(e)}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Transformation failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logger.info(\"Data transformation task completed.\")\n",
    "\n",
    "# Task: Load data into PostgreSQL\n",
    "@task(name=\"Load Data to PostgreSQL\")\n",
    "@timing_decorator\n",
    "@with_postgresql_connection\n",
    "def load_data(cur, df_clustering):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        # Create table if it doesn't exist\n",
    "        logger.info(\"Creating table if not exists...\")\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS wheat_seeds_clustering (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            area REAL,\n",
    "            perimeter REAL,\n",
    "            compactness REAL,\n",
    "            length_of_kernel REAL,\n",
    "            width_of_kernel REAL,\n",
    "            asymmetry_coefficient REAL,\n",
    "            length_of_kernel_groove REAL\n",
    "        )\n",
    "        \"\"\"\n",
    "        cur.execute(create_table_query)\n",
    "        logger.info(\"Table created/verified successfully.\")\n",
    "        \n",
    "        # Insert data from DataFrame\n",
    "        logger.info(\"Inserting data into PostgreSQL...\")\n",
    "        for _, row in df_clustering.iterrows():\n",
    "            insert_query = \"\"\"\n",
    "            INSERT INTO wheat_seeds_clustering \n",
    "            (area, perimeter, compactness, length_of_kernel, width_of_kernel, asymmetry_coefficient, length_of_kernel_groove)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\"\n",
    "            cur.execute(insert_query, tuple(row))\n",
    "        \n",
    "        logger.info(f\"Successfully inserted {len(df_clustering)} records into PostgreSQL.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data to PostgreSQL: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Analyze correlations\n",
    "@task(name=\"Analyze Correlations\")\n",
    "@timing_decorator\n",
    "def analyze_correlations(df_clustering):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Analyzing feature correlations...\")\n",
    "        \n",
    "        # Calculate the correlation matrix\n",
    "        correlation_matrix = df_clustering.corr()\n",
    "\n",
    "        # Find the pair of variables with the lowest absolute correlation\n",
    "        lower_triangle = correlation_matrix.mask(np.triu(np.ones(correlation_matrix.shape)).astype(bool))\n",
    "        lowest_corr = lower_triangle.stack().abs().min()\n",
    "        lowest_corr_pair = lower_triangle.stack().abs().idxmin()\n",
    "\n",
    "        # Print the lowest correlation and the corresponding pair of variables\n",
    "        logger.info(f\"The lowest absolute correlation is {lowest_corr:.4f}, between {lowest_corr_pair}\")\n",
    "\n",
    "        # Plot a heatmap of the correlation matrix for visualization\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title('Correlation Matrix of Seed Features')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'correlation_heatmap.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Correlation analysis completed and heatmap saved to {output_path}.\")\n",
    "        \n",
    "        return lowest_corr_pair\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in correlation analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Elbow Method Analysis\n",
    "@task(name=\"Elbow Method Analysis\")\n",
    "@timing_decorator\n",
    "def elbow_method_analysis(df_clustering):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing Elbow Method analysis...\")\n",
    "        \n",
    "        # Select the two variables for clustering\n",
    "        X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "        # Determine the optimal number of clusters using the Elbow Method\n",
    "        inertia = []\n",
    "        for i in range(1, 11):\n",
    "            kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "            kmeans.fit(X)\n",
    "            inertia.append(kmeans.inertia_)\n",
    "\n",
    "        # Plot the Elbow Method results\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(range(1, 11), inertia, marker='o')\n",
    "        plt.title('Elbow Method for Optimal K')\n",
    "        plt.xlabel('Number of Clusters (K)')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'elbow_method.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        logger.info(f\"Elbow Method analysis completed and plot saved to {output_path}.\")\n",
    "        \n",
    "        # Based on the Elbow plot, choose the optimal number of clusters\n",
    "        optimal_k = 3\n",
    "        return optimal_k\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in Elbow Method analysis: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Perform clustering without centroids\n",
    "@task(name=\"Perform KMeans Clustering\")\n",
    "@timing_decorator\n",
    "def perform_kmeans_clustering(df_clustering, optimal_k=3):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing K-means clustering...\")\n",
    "        \n",
    "        # Variables para clustering\n",
    "        X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "        # Entrenar KMeans con K óptimo\n",
    "        kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        df_clustering['cluster'] = kmeans_model.fit_predict(X)\n",
    "\n",
    "        # Visualizar resultados sin centroides\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(\n",
    "            df_clustering['Asymmetry_coefficient'], \n",
    "            df_clustering['Length_of_kernel_groove'], \n",
    "            c=df_clustering['cluster'], cmap='viridis'\n",
    "        )\n",
    "        plt.title(f'K-means Clustering of Seeds (K={optimal_k})')\n",
    "        plt.xlabel('Asymmetry_coefficient')\n",
    "        plt.ylabel('Length_of_kernel_groove')\n",
    "        plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'kmeans_clustering.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        logger.info(f\"Clustering completed and visualization saved to {output_path}.\")\n",
    "        \n",
    "        return df_clustering\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in clustering: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# NEW TASK: Perform clustering with centroids\n",
    "@task(name=\"Perform KMeans Clustering with Centroids\")\n",
    "@timing_decorator\n",
    "def perform_kmeans_clustering_with_centroids(df_clustering, optimal_k=3):\n",
    "    logger = get_run_logger()\n",
    "    try:\n",
    "        logger.info(\"Performing K-means clustering with centroids...\")\n",
    "        \n",
    "        # Variables para clustering\n",
    "        X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "        # Entrenar KMeans con K óptimo\n",
    "        kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        df_clustering['cluster'] = kmeans_model.fit_predict(X)\n",
    "\n",
    "        # Centroides\n",
    "        centroids = kmeans_model.cluster_centers_\n",
    "\n",
    "        # Visualizar resultados con centroides\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(\n",
    "            df_clustering['Asymmetry_coefficient'], \n",
    "            df_clustering['Length_of_kernel_groove'], \n",
    "            c=df_clustering['cluster'], cmap='viridis'\n",
    "        )\n",
    "        plt.scatter(\n",
    "            centroids[:, 0], centroids[:, 1], \n",
    "            c='red', marker='X', s=200, label='Centroids'\n",
    "        )\n",
    "        plt.title(f'K-means Clustering of Seeds (K={optimal_k})')\n",
    "        plt.xlabel('Asymmetry_coefficient')\n",
    "        plt.ylabel('Length_of_kernel_groove')\n",
    "        plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Save plot to output directory\n",
    "        output_path = os.path.join(OUTPUT_DIRECTORY, 'kmeans_clustering_with_centroids.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        logger.info(f\"Clustering with centroids completed and visualization saved to {output_path}.\")\n",
    "        \n",
    "        return df_clustering, centroids\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in clustering with centroids: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Main Flow: Orchestrate the pipeline\n",
    "@flow(name=\"Wheat Seed Analysis Pipeline\")\n",
    "@report_download_size(DOWNLOAD_DIRECTORY)\n",
    "def complete_analysis_pipeline():\n",
    "    create_directories()\n",
    "    kaggle_api = api_authenticate()\n",
    "    download_dataset(kaggle_api)\n",
    "    df_seeds = load_csv()\n",
    "    df_clustering = transform_data(df_seeds)\n",
    "    load_data(df_clustering)\n",
    "    lowest_corr_pair = analyze_correlations(df_clustering)\n",
    "    optimal_k = elbow_method_analysis(df_clustering)\n",
    "    df_clustered = perform_kmeans_clustering(df_clustering, optimal_k)\n",
    "    df_clustered_with_centroids, centroids = perform_kmeans_clustering_with_centroids(df_clustering, optimal_k)\n",
    "    \n",
    "    return df_clustered, lowest_corr_pair, centroids\n",
    "\n",
    "# Run the flow\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df_clustered, lowest_corr_pair, centroids = complete_analysis_pipeline()\n",
    "        print(f\"Analysis completed. Lowest correlation pair: {lowest_corr_pair}\")\n",
    "        print(f\"Cluster centroids: {centroids}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline execution failed: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38e0ab",
   "metadata": {},
   "source": [
    "### Basic (Unsupervised) Machine Learning analytics method\n",
    " Determine, by clustering, a sound number of species within the wheat seed dataset\n",
    "\n",
    " Firstly, identify the less correlated pair of features and use them as the representation for the instances in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a54896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# # Calculate the correlation matrix.\n",
    "# correlation_matrix = df_clustering.corr()\n",
    "\n",
    "# # Find the pair of variables with the lowest absolute correlation.\n",
    "# # We take the upper triangle of the correlation matrix and flatten it, and ignore the diagonal (which are all 1).\n",
    "# # We then find the minimum value and the corresponding row and column.\n",
    "# lower_triangle = correlation_matrix.mask(np.triu(np.ones(correlation_matrix.shape)).astype(bool))\n",
    "# lowest_corr = lower_triangle.stack().abs().min()\n",
    "# lowest_corr_pair = lower_triangle.stack().abs().idxmin()\n",
    "\n",
    "# # Print the lowest correlation and the corresponding pair of variables.\n",
    "# print(f\"The lowest absolute correlation is {lowest_corr:.4f}, between {lowest_corr_pair}\")\n",
    "\n",
    "# # Plot a heatmap of the correlation matrix for visualization.\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "# plt.title('Correlation Matrix of Seed Features')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.yticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('correlation_heatmap.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dc263",
   "metadata": {},
   "source": [
    "Now, use the `KMeans` clustering method to perform an unsupervised approach to the identification of the number of species in the dataset, according to the observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c0a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# # Select the two variables for clustering.\n",
    "# X = df_clustering[['Asymmetry_coefficient', 'Length_of_kernel_groove']]\n",
    "\n",
    "# # Determine the optimal number of clusters using the Elbow Method.\n",
    "# inertia = []\n",
    "# for i in range(1, 11):\n",
    "#     kmeans = KMeans(n_clusters=i, random_state=42, n_init=10)\n",
    "#     kmeans.fit(X)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "\n",
    "# # Plot the Elbow Method results.\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(range(1, 11), inertia, marker='o')\n",
    "# plt.title('Elbow Method for Optimal K')\n",
    "# plt.xlabel('Number of Clusters (K)')\n",
    "# plt.ylabel('Inertia')\n",
    "# plt.xticks(range(1, 11))\n",
    "# plt.grid(True)\n",
    "# plt.savefig('elbow_method.png')\n",
    "# plt.show()\n",
    "\n",
    "# # Based on the Elbow plot, choose the optimal number of clusters.\n",
    "# # For this dataset, the 'Class' column suggests ?? classes, and the elbow method plot shows a good elbow at k=??.\n",
    "# optimal_k = 3\n",
    "\n",
    "# # Perform K-means clustering with the optimal number of clusters.\n",
    "# kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "# df_clustering['cluster'] = kmeans_model.fit_predict(X)\n",
    "\n",
    "# # Visualize the clustering results.\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# scatter = plt.scatter(df_clustering['Asymmetry_coefficient'], df_clustering['Length_of_kernel_groove'], c=df_clustering['cluster'], cmap='viridis')\n",
    "# plt.title('K-means Clustering of Seeds (K=3)')\n",
    "# plt.xlabel('Asymmetry_coefficient')\n",
    "# plt.ylabel('Length_of_kernel_groove')\n",
    "# plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "# plt.grid(True)\n",
    "# plt.savefig('kmeans_clustering_plot.png')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027d2f4",
   "metadata": {},
   "source": [
    "__Challenges (Workshop 3, part 2):__\n",
    "1. Organize the code of the example and complete the data pipeline: \n",
    "    - Use `try-except-finally` blocks as required \n",
    "    - Every individual process must be wrapped as a `task` using the corresponding decorator and its parameters when necessary. \n",
    "    - Create a `transform_data` task focused on data cleansing\n",
    "    - Create a `load_data` task to create a table in a Dockerized PostgreSQL database and populate with with the clustering-oriented Dataframe\n",
    "    - Invoke the tasks in the proper order in the `flow`\n",
    "    - Use the `timing_decorator` to report the duration of each task \n",
    "1. Using the function get_directory_size, create a decorator to get and report the size of the downloaded dataset (size in bytes of the download folder)\n",
    "1. Report the size in the previous question in a human readable unit\n",
    "1. Use the attribute kmeans.cluster_centers_ and scatter plot to add the centroids of the best KMeans model (best K parameter) to the scatter plot\n",
    "    - `centroids = kmeans.cluster_centers_`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
